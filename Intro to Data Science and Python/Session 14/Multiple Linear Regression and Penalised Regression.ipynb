{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import linalg\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhdata=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredata=bhdata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhdata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bhdata.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=bhdata.feature_names\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(featuredata,columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target']=bhdata.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.distplot(data['target'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= data.corr().round(2)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "# annot = True to print the values inside the square\n",
    "ax=sns.heatmap(data=corr, annot=True)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "features = ['LSTAT', 'RM']\n",
    "target = data['target']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features) , i+1)\n",
    "    x = data[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker='o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Median Housing Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#How can we look at all the data at one.\n",
    "#Pairwise correlation plot\n",
    "\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'RM', y = 'target', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUmmary Statistics\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.20, shuffle=True,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.shape,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = data_train.iloc[:,0:(data_train.shape[1]-1)].values\n",
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain=data_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = data_test.iloc[:,0:(data_test.shape[1]-1)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTest=data_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression Model\n",
    "reg= linear_model.LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(XTrain, YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\", reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(XTrain, YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.singular_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(colnames,reg.coef_),columns=['Input_features','Model_Coefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set results \n",
    "Y_pred = reg.predict(XTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scatter graph to show the prediction  \n",
    "# results - 'y_actual' value vs 'y_pred' value \n",
    "plt.scatter(YTest, Y_pred, c = 'green') \n",
    "plt.xlabel(\"Actual Housing Price: in $1000's\") \n",
    "plt.ylabel(\"Predicted Housing Price: in $1000's\") \n",
    "plt.title(\"Actual value vs predicted value : Linear Regression\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted R-Square\n",
    "def AdjustedRSquare(model,X,Y):\n",
    "    YHat= model.predict(X)\n",
    "    n,k = X.shape\n",
    "    sse = np.sum(np.square(YHat-Y),axis=0)\n",
    "    sst = np.sum(np.square(Y-np.mean(Y)),axis=0)\n",
    "    R2 = 1 - sse/sst\n",
    "    adjR2 = R2 - (1- R2)*(float(k)/(n-k-1))\n",
    "    return adjR2, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.xspdf.com/help/50077476.html\n",
    "#Return P-Value\n",
    "def ReturnPValue(model,X,Y):\n",
    "    YHat= model.predict(X)\n",
    "    n,k = X.shape\n",
    "    sse = np.sum(np.square(YHat-Y),axis=0)\n",
    "    x = np.hstack((np.ones((n,1)),np.matrix(X)))\n",
    "    df = float(n-k-1)\n",
    "    sampleVar = sse/df\n",
    "    sampleVarianceX = x.T*x\n",
    "    covarianceMatrix = linalg.sqrtm(sampleVar*sampleVarianceX.I)\n",
    "    se = covarianceMatrix.diagonal()[1:]\n",
    "    betasTstat = np.zeros(len(se))\n",
    "    for i in range(len(se)):\n",
    "        betasTstat[i] = model.coef_[i]/se[i]\n",
    "    betasPvalue = 1- stats.t.cdf(abs(betasTstat),df)\n",
    "    return betasPvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.BetasPValue=ReturnPValue(reg,XTrain,YTrain)\n",
    "reg.BetasPValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.adjR2, reg.R2 = AdjustedRSquare(reg,XTrain,YTrain)\n",
    "print(reg.adjR2, reg.R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X = XTrain\n",
    "y = YTrain\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null : Beta estimates = 0\n",
    "# Alt : Beta Estimates != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\", reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = est2.pvalues\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two methods of reporting the error from the regression model\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "#Mean Sum of Square error (MSSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ErrorMetric(model,X,Y):\n",
    "    Yhat = model.predict(X)\n",
    "    MAPE = np.mean(abs(Y-Yhat)/Y)*100\n",
    "    MSSE = np.mean(np.square(Y-Yhat))\n",
    "    return MAPE, MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.TrainMAPE, reg.TrainMSSE = ErrorMetric(reg,XTrain,YTrain)\n",
    "reg.TrainMAPE, reg.TrainMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.MAPE, reg.MSSE = ErrorMetric(reg,XTest,YTest)\n",
    "reg.MAPE, reg.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "\n",
    "print('MAE', mean_absolute_error(YTest, Y_pred))\n",
    "print('MSE', mean_squared_error(YTest, Y_pred))\n",
    "print('RMSE', np.sqrt(mean_squared_error(YTest, Y_pred)))\n",
    "print('R squared error', r2_score(YTest, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot((YTest-Y_pred),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multi Collinearity\n",
    "# Coefficient estimates may not be reliable\n",
    "# Consider removing variables with a high Variance Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "print('Variance Inflation Factors (VIF)')\n",
    "print('> 10: An indication that multicollinearity may be present')\n",
    "print('> 100: Certain multicollinearity among the variables')\n",
    "print('-------------------------------------')\n",
    "       \n",
    "# Gathering the VIF for each variable\n",
    "VIF = [variance_inflation_factor(featuredata, i) for i in range(featuredata.shape[1])]\n",
    "for idx, vif in enumerate(VIF):\n",
    "    print('{0}: {1}'.format(colnames[idx], vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for homoscedasticity, which is the same variance within our error terms\n",
    "# Heteroscedasticity means we don’t have an even variance across the error terms.\n",
    "# Significance tests for coefficients due to the standard errors being biased. \n",
    "# Additionally, the confidence intervals will be either too wide or too narrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = abs(YTest)-abs(Y_pred)\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the residuals\n",
    "plt.subplots(figsize=(12, 6))\n",
    "ax = plt.subplot(111)  # To remove spines\n",
    "plt.scatter(x=residuals.index, y=residuals, alpha=0.5)\n",
    "plt.plot(np.repeat(0, residuals.index.max()), color='darkorange', linestyle='--')\n",
    "ax.spines['right'].set_visible(False)  # Removing the right spine\n",
    "ax.spines['top'].set_visible(False)  # Removing the top spine\n",
    "plt.title('Residuals')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There don’t appear to be any obvious problems with that and variance appears to be uniform across the error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existence of outliers inflates the B coefficients, It has the capacity to destabilize the estimated statistics\n",
    "# and may represent incorrect R2 and Adj R2\n",
    "\n",
    "# Outliers can be managed by removing them or replacing them with various interpolation methods\n",
    "# It can be replaced by median values/mean values/percentile based approach/caping based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.DIS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['DIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(data['INDUS'], data['TAX'])\n",
    "ax.set_xlabel('Proportion of non-retail business acres per town')\n",
    "ax.set_ylabel('Full-value property-tax rate per $10,000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    plt.figure()\n",
    "    data.boxplot([column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((data < (Q1 - 3 * IQR)) | (data > (Q3 + 3 * IQR))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_out = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "data_df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score of an observation is a distance from the mean in the units of standard deviation\n",
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(data))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(z).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "print(np.where(z > threshold))\n",
    "z[np.where(z > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z[55][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_o = data[(z < 3).all(axis=1)]\n",
    "data_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I drop redundant variables, then it will significantly improve the model accuracy\n",
    "# Stepwise feature selection is an iterative method to identify the best features\n",
    "# Helps in removing High multi colliearity among the predictors\n",
    "# the Variable selection for the predictive model can happen in three different ways:\n",
    "# Forward Selection of Variables\n",
    "# Backward Selection of Variables\n",
    "# Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Selection:\n",
    "# Null model, add another variable and continue to do that until it is adding up the r-square values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Accuracy\n",
    "# ADj R2 -- 0.7158605022207648 \n",
    "# R2 --- 0.7250262924717079 \n",
    "# MAPE - 16.909381848539258\n",
    "# MSSE - 23.964571384956862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "erroR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevMAPE, prevMSSE= ErrorMetric(reg,XTest,YTest)\n",
    "print(prevMAPE, prevMSSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevadjR2, prevR2 = AdjustedRSquare(reg,XTrain,YTrain)\n",
    "#prevadjR2, prevR2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (erroR > 0.001):\n",
    "    ind = np.where(reg.BetasPValue > alpha)[0]\n",
    "    if(len(ind)==0):\n",
    "        ind = np.argmax(reg.BetasPValue)\n",
    "    \n",
    "    XTrain = np.delete(XTrain, ind, axis=1)\n",
    "    XTest = np.delete(XTest, ind, axis= 1)\n",
    "    \n",
    "    reg.fit(XTrain, YTrain)\n",
    "    \n",
    "    reg.BetasPValue = ReturnPValue(reg,XTrain,YTrain)\n",
    "    MAPE, MSSE = ErrorMetric(reg,XTest,YTest)\n",
    "    print(MSSE)\n",
    "    #adjR2, R2 = AdjustedRSquare(reg,XTrain,YTrain)\n",
    "    \n",
    "    erroR = prevMSSE - MSSE\n",
    "    #erroR = adjR2 - prevadjR2\n",
    "    \n",
    "print(erroR,MSSE)\n",
    "#print(erroR,adjR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.BetasPValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(XTrain).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RAD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RAD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_Dummies = pd.get_dummies(data.RAD,prefix=\"RAD\").iloc[:,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_Dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for K levels, we will create K-1 dummy variables\n",
    "# If you have 4 categories, then create three dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropped the first column\n",
    "RAD_Dummies = pd.get_dummies(data.RAD,prefix=\"RAD\").iloc[:,1:]\n",
    "RAD_Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata=pd.concat([data,RAD_Dummies],axis=1)\n",
    "modeldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata_df=modeldata.iloc[:,list(range(8)) + list(range(9,modeldata.shape[1]))]\n",
    "modeldata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative approach\n",
    "modeldata_df1=pd.get_dummies(data, columns=['RAD'],drop_first=True)\n",
    "modeldata_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CHAS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CHAS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata_df2=pd.get_dummies(data, columns=['RAD','CHAS'],drop_first=True)\n",
    "modeldata_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(modeldata_df, test_size=0.20, shuffle=True,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into further XTrain, YTrain\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = df_train.iloc[:,list(range(12))+list(range(13,df_train.shape[1]))].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain = df_train['target']\n",
    "YTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape,YTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = df_test.iloc[:,list(range(12))+list(range(13,df_test.shape[1]))].values\n",
    "YTest = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest.shape,YTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the dataset with Dummy variables\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.score(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.MAPE, regr.MSSE = ErrorMetric(regr,XTest,YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.MAPE, regr.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.adjR2, regr.R2 = AdjustedRSquare(regr,XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.adjR2, regr.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Accuracy\n",
    "# ADj R2 -- 0.7158605022207648 \n",
    "# R2 --- 0.7250262924717079 \n",
    "# MAPE - 16.909381848539258\n",
    "# MSSE - 23.964571384956862\n",
    "\n",
    "# After Creation of dummy variables-- Model Accuracy\n",
    "# ADj R2 -- 0.7241554031130855 \n",
    "# R2 --- 0.737844961271245 \n",
    "# MAPE - 17.16019696950829\n",
    "# MSSE - 24.949060732511533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is not much improvement in accuracy with inclusion of dummy variable\n",
    "#It is important to explore the existence of non linear relationship\n",
    "\n",
    "#Polynomial features --> Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(featuredata).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(featuredata)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to pass the degree of the polynomial. Here we are generating polynomial features of degree =2\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpoly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpoly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xpoly).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the Polynomial feature names\n",
    "df1 = pd.DataFrame(featuredata,columns=colnames)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit_transform(df1)\n",
    "polynomial_feature_names=poly.get_feature_names(df1.columns)\n",
    "polynomial_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(polynomial_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpoly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = bhdata.target\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Linear regression model on the polynomial features\n",
    "regr2 = linear_model.LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2.fit(Xpoly,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2.score(Xpoly,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr2.MAPE, regr2.MSSE = ErrorMetric(regr2,Xpoly,Y)\n",
    "regr2.MAPE, regr2.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr2.adjR2, regr2.R2 = AdjustedRSquare(regr2,Xpoly,Y)\n",
    "regr2.adjR2, regr2.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Accuracy\n",
    "# ADj R2 -- 0.7158605022207648 \n",
    "# R2 --- 0.7250262924717079 \n",
    "# MAPE - 16.909381848539258\n",
    "# MSSE - 23.964571384956862\n",
    "\n",
    "# After Inclusion of dummy variables\n",
    "# ADj R2 -- 0.7241554031130855 \n",
    "# R2 --- 0.737844961271245 \n",
    "# MAPE - 17.16019696950829\n",
    "# MSSE - 24.949060732511533\n",
    "\n",
    "# After Inclusion of Polynomial Features\n",
    "# ADj R2 -- 0.9103557309584304 \n",
    "# R2 --- 0.9289946383829152 \n",
    "# MAPE - 9.39831696764503\n",
    "# MSSE - 5.994241112422332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we generalize the model results of the polynomial model\n",
    "# Overfitting is something we need to address - Whenever model given unusually high accuracy\n",
    "# Sometimes fitting large number of features can also lead to overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To restrict model overfitting, we perform regularisation\n",
    "# Regularisation penalises the coeff with large values and helps us in avoiding large coefficients in a predictive model\n",
    "# Regularisation helps us to produces a model which is more generalised \n",
    "# Regularised regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO(least absolute shrinkage and selection operator) - L1 Regularisation\n",
    "# Ridge - L2 Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpoly.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, YTrain, Ytest = train_test_split(Xpoly, Y, test_size=0.25, shuffle=True,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, YTrain.shape, XTest.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha => Regularised Parameter\n",
    "lasso = Lasso(alpha=2)\n",
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimportant feature's Beta estimates are compressed to 0\n",
    "names = [polynomial_feature_names[i] for i in list(np.where(lasso.coef_ != 0.0)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.MAPE, lasso.MSSE = ErrorMetric(lasso,XTest,Ytest)\n",
    "lasso.MAPE, lasso.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.adjR2, lasso.R2 = AdjustedRSquare(lasso,XTrain,YTrain)\n",
    "lasso.adjR2, lasso.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.MAPE, ridge.MSSE = ErrorMetric(ridge,XTest,Ytest)\n",
    "ridge.MAPE, ridge.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.adjR2, ridge.R2 = AdjustedRSquare(ridge,XTrain,YTrain)\n",
    "ridge.adjR2, ridge.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the correct Alpha is very important\n",
    "# How to get the optimum value of Alpha\n",
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(bhdata.data, bhdata.target)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Considering the Best estimator for alpha\n",
    "ridge1 = Ridge(alpha=0.99321)\n",
    "\n",
    "ridge1.fit(XTrain,YTrain)\n",
    "ridge1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1.MAPE, ridge1.MSSE = ErrorMetric(ridge1,XTest,Ytest)\n",
    "ridge1.MAPE, ridge1.MSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1.adjR2, ridge1.R2 = AdjustedRSquare(ridge1,XTrain,YTrain)\n",
    "ridge1.adjR2, ridge1.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
